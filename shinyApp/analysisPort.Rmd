---
title: "Multi-agent Data Analysis"
output:
  html_document: default
  pdf_document: default
---

# Simulation Analysis

Interactive Simulation Analysis

- Number of replication
- Parameter recommendation (through analytical models below)


```{r}

library(data.table)
library(sqldf)
library(plyr)
library(dplyr)
library(readxl)
library(datasets)
library(corrplot)
library(data.table)
library(ggplot2)

######### Here meet must be customized by case ###################################################################################
######### set working directory to where your data is
data2 <- read.csv('./data/alldata2.csv')

result_col = "NonTeamCapture"

##specify response variable (y) and name it result
colnames(data2)[colnames(data2) == result_col] <- 'result'
data <- data2

dataTypes <- sapply(data, class)
resultCol <- data['result']

# Variables varied: {values they had}
# max_speed_t_1 = vel_max_t_1: {40 50}
# max_speed_t_2_predator = vel_max_t_2: {10 20 30 40 50}
# turn_rate_max_t_1: {0.25 0.5 0.75}
# turn_rate_max_predator: {0.25 0.5 0.75}
# allow_prey_switching_t_2_predator: {True False}
# 180 combinations

########provide column names of numeric variables
numericCol <- c("vel_max.t.1",
"vel_max.predator",
"pitch_rate_max.predator",
"turn_rate_max.predator")
# numericCol <- colnames(data[sapply(data, is.numeric)])

########provide column names of category variables
categoryCol <- c("team_id",
"allow_prey_switching.t.2.predator")
# categoryCol <- 

##read useful varaibles only (specified above)
mydata <- cbind(data$result, data[,numericCol] , data[,categoryCol])
colnames(mydata)[colnames(mydata) == 'data$result'] <- 'result'

##Clean missing data
mydata <- na.omit(mydata)
#mydataOriginal <- mydata
#mydata <- mydata[mydata$team_id > 1,]

lastCol = length(mydata[1])
for(i in 1:length(mydata$result)){
  mydata$predictors[i] = paste(mydata[i,2:lastCol],  collapse=" ")
}
combinations <- levels(factor(mydata$predictors))

# stabilityTable <- ddply(mydata, c("predictors"), summarise,
#                N    = length(result),
#                mean = mean(result),
#                sd   = sd(result),
#                cov   = sd(result) / mean(result)  )
# stabilityTable[order(stabilityTable$cov),]

stabilityTable2 <- ddply(mydata, cbind(numericCol, categoryCol), summarise,
               N    = length(result),
               mean = mean(result),
               sd   = sd(result),
               cov   = sd(result) / mean(result)  )
stabilityTable2[order(stabilityTable2$cov),]


# # Set a different color for each group
# ggplot(mydata, aes(x=predictors, y=result, fill=predictors)) + 
#       geom_boxplot(alpha=0.3) + theme(legend.position="none")


```






# Regression analysis

Method - automatic predictive modeling 

1. Data preprocessing

a. Remove all the missing values
b. Divde feature(paramters) into numerical variables and categorical variables
c. Remove non informative variables(the number of factors = 1)
d. data transformation(log, squared root, squared)

```{r}
library(data.table)
library(sqldf)
library(plyr)
library(dplyr)
library(readxl)
library(datasets)
library(corrplot)

######### Here meet must be customized by case ###################################################################################
######### set working directory to where your data is
#setwd("D:/CSE_project")
#setwd("~/Desktop/cse")
data1 <- read.csv('./data/alldata2.csv')
data <- data1
#attach(data)
#hist(NonTeamCapture)
#summary(data)



#totalCapture_temp <- sqldf("Select SUM(score), task_num from data GROUP BY task_num ")
#names(totalCapture_temp) <- c("TotalCapture", "task_num")
#data2 <- join(x=data, y =totalCapture_temp, by= "task_num", type="left",match="first")

#######First provide column name if want to. name the response variable(y) as result
names(data)<-c("team_id",
"TeamCapture",
"NonTeamCapture",
"job_num",
"task_num",
"results_dir",
"num_rows",
"align_weight_t_1",
"avoid_nonteam_weight_t_1",
"avoid_team_weight_t_1",
"centroid_weight_t_1",
"comms_range_t_1",
"fov_az_t_1",
"fov_el_t_1",
"goal_weight_t_1",
"max_speed_t_1",
"sphere_of_influence_t_1",
"vel_max_t_1",
"pitch_rate_max_predator",
"turn_rate_max_predator",
"vel_max_predator",
"allow_prey_switching_t_2_predator",
"capture_range_t_2_predator",
"max_pred_speed_t_2_predator",
"allow_prey_switching_t_3_predator",
"capture_range_t_3_predator",
"max_pred_speed_t_3_predator") 

# data_temp <- sqldf("Select * from data WHERE num_rows > 1")
# data_temp <- sqldf("Select task_num, Sum(result) from data_temp GROUP BY task_num")
# names(data_temp) <- c( "task_num", "TotalCapture")
# data2 <- join(x=data, y =data_temp, by= "task_num", type="right",match="first")
# data2$result <- NULL
# colnames(data2)[colnames(data2) == 'TotalCapture'] <- 'result'
# data <- data2

##specify response variable (y) and name it result
colnames(data)[colnames(data) == 'NonTeamCapture'] <- 'result'

########provide column names of meaningful numeric variables
numericCol <- c("align_weight_t_1",
"avoid_nonteam_weight_t_1",
"avoid_team_weight_t_1",
"centroid_weight_t_1",
"comms_range_t_1",
"fov_az_t_1",
"fov_el_t_1",
"goal_weight_t_1",
"max_speed_t_1",
"sphere_of_influence_t_1",
"vel_max_t_1",
"pitch_rate_max_predator",
"turn_rate_max_predator",
"vel_max_predator",
"capture_range_t_2_predator",
"max_pred_speed_t_2_predator",
"capture_range_t_3_predator",
"max_pred_speed_t_3_predator")

########provide column names of meaningful category variables
categoryCol <- c("team_id",
"allow_prey_switching_t_2_predator",
"allow_prey_switching_t_3_predator")

##read useful varaibles only (specified above)
mydata <- cbind(data$result, data[,numericCol] , data[,categoryCol])
colnames(mydata)[colnames(mydata) == 'data$result'] <- 'result'

##Clean missing data
mydata <- na.omit(mydata)
mydataOriginal <- mydata

##Drop columns of no information (only one value exists)
NumericColToAdd <- c()
for(col in numericCol ){
  if(sd(mydata[,col]) > 0){
    NumericColToAdd <- cbind(NumericColToAdd, col)
  }
}
CatColToAdd <- c()
for(col in categoryCol ){
  temp <- levels(factor(mydata[,col]))
  if( length(temp[temp != ""]) > 1){
    CatColToAdd <- cbind(CatColToAdd, col)
  }
}

mydata <- cbind(mydata$result, mydata[,NumericColToAdd] , mydata[,CatColToAdd])
colnames(mydata) <- cbind("result", NumericColToAdd, CatColToAdd)


####Basic Correlation analysis for numeric varibles
Corr <- cor(mydata[,cbind("result", NumericColToAdd)])
corrplot(Corr, method="circle")

######Basic one-way Anova for category varaibles
# anova <- aov(result ~ team_id, data=mydata)
# h2<-sqldf("select result from mydata where team_id =0")
# h1<-sqldf("select result from mydata where team_id =1")
# # Histogram Colored (blue and red)
# pval = summary(anova)[[1]][1,5]
# hist(h1[,1], col=rgb(runif(1,0,1), runif(1,0,1), runif(1,0,1), 0.5), main=paste("Historgram by Team ID with ANOVA p-value =", pval) , xlab="result")
# hist(h2[,1], col=rgb(runif(1,0,1), runif(1,0,1), runif(1,0,1), 0.5), add=T)
# box()


######data transformation
# for(col in NumericColToAdd ){
# 
#   transformed <- mydata[,col]
#   maxCorr = abs(Corr["result", col])
#   
#   if(min(mydata[,col]) > 0){
#   
#     candidate <- log(mydata[,col])
#     canCorr = abs(cor(mydata[,"result"], candidate))
#     if(canCorr > maxCorr){
#       maxCorr = canCorr
#       transformed <- candidate
#     }
#     
#     candidate <- sqrt(mydata[,col])
#     canCorr = abs(cor(mydata[,"result"], candidate))
#     if(canCorr > maxCorr){
#       maxCorr = canCorr
#       transformed <- candidate
#     }
#     
#   }
# 
#   
#   candidate <- mydata[,col]^2
#   canCorr = abs(cor(mydata[,"result"], candidate))
#   if(canCorr > maxCorr){
#     maxCorr = canCorr
#     transformed <- candidate
#   }
# 
#   mydata[,col] <- transformed
# }
# Corr2 <- cor(mydata)
# par(mfrow=c(1,2))
# corrplot(Corr, method="circle")
# corrplot(Corr2, method="circle")
```

2. Method

- Multivariate linear regression
- Linear regression with AIC
- Ridge regression
- LASSO
- Principal component regresson(using PCA)
- Partial least squares
- Random Forest Regression
- Neural networks



```{r}
# Choose the models
# 1. Multivariate linear regression
# 2. Linear regression with backward elimination
# 3. Principal component regresson(using PCA)
# 4. Partial least squares
# 5. Random Forest Regression
# 6. Neural networks
set.seed(123)
model_selection = 5

# Choose the response variable that you want to predict in terms of explanatory variables
# y = result
# X = 
# For example,
# y = total_scores for each simulation 
# X = max_speed, max_speed_predator2

# Splitting the dataset into the training set and test set
library(caTools)
boxcox = FALSE

if(boxcox){
  bc <- boxcox(result ~ ., data = mydata, lambda = seq(-1, 1, length = 10))
  lambda <- bc$x[which.max(bc$y)]
  
  mydata$result_old <- mydata$result
  mydata$result <- NULL
  mydata$result <- (mydata$result_old^lambda-1)/lambda
}

dataset = mydata
split = sample.split(data$result, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)


# Fitting the model to the training set
if (model_selection == 1) { # Multivarite linear regression model
  model = lm(formula = result ~., data = training_set)
  y_pred<- predict(model,test_set)
} else if(model_selection == 2) { # Linear regression with backward selection
  lmtest <- lm(result ~ . , data=training_set)
  lmSummary <- summary(lmtest)
  pValues <- t(coef(lmSummary)[,4])
  varNames <- colnames(pValues)
  NewVar <- c()
  for(i in 2:length(varNames)){
    if(pValues[i] < 0.05){
      NewVar <- cbind(NewVar, varNames[i])
    }
  }
  backward = length(varNames) - 1 - length(NewVar)
  while(backward > 0){
    backward = length(NewVar)
    if(length(NewVar) > 0){
      NextData <- training_set[, cbind("result", NewVar)]
      lmtest2 <- lm(result ~ . , data=NextData)
      lmSummary2 <- summary(lmtest2)
      pValues <- t(coef(lmSummary2)[,4])
      varNames <- colnames(pValues)
      NewVar <- c()
      for(i in 2:length(varNames)){
        if(pValues[i] < 0.05){
          NewVar <- cbind(NewVar, varNames[i])
        }
      }
      backward = backward - length(NewVar)
    }
  }
  
  y_pred<- predict(lmtest2,test_set)
  
} else if (model_selection == 3) { # Principal component regresson
  require(pls)
  model = pcr(result~., data = training_set, ncomp=dim(training_set)[2]-1, validation="CV")
  pcrCV<- RMSEP(model,estimate = "CV")
  plot(pcrCV, main(""))
  param_num<-which.min(pcrCV$val)
  y_pred = predict(model,test_set,ncop = param_num)
} else if (model_selection == 4) { # Partial least squares
  model = plsr(result~., data = training_set, ncomp = dim(training_set)[2]-1, validation ="CV")
  plsCV<- RMSEP(model, estimate = "CV")
  plot(plsCV, main = "")
  param_num <- which.min(plsCV$val)
  y_pred = predict(model,test_set,ncomp = param_num)
} else if (model_selection == 5) { # Random Forest Regression
  library(randomForest)
  model = randomForest(x = training_set[,-1],y = training_set$result, subset = training_set, ntree = 20)
  y_pred <- predict(model,test_set)
} else if (model_selection == 6) { #  Neural networks
  require(nnet)
  model = nnet(result~., data = training_set,size = 2)
  y_pred<- predict(model,test_set)
}

summary(model)
(mean((y_pred-test_set$result)^2))
par(mfrow=c(2,2))#drawing in 2 by 2 format
plot(model,which=c(1:4), col = "cornflowerblue")
plot(model$fitted.values, model$residuals)

```
